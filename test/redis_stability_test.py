#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Redisè¿æ¥ç¨³å®šæ€§æµ‹è¯•ç¨‹åº
æµ‹è¯•è¿æ¥æ± é…ç½®å’Œé‡è¯•æœºåˆ¶çš„æ•ˆæœ
"""

import redis
import time
import threading
import concurrent.futures
import statistics
from datetime import datetime
import json

class RedisStabilityTester:
    def __init__(self, host='localhost', port=6379, db=0, password=None):
        self.host = host
        self.port = port
        self.db = db
        self.password = password
        
        # è¿æ¥æ± é…ç½® - å¯¹åº”Javaé…ç½®çš„å‚æ•°
        self.pool = redis.ConnectionPool(
            host=host,
            port=port,
            db=db,
            password=password,
            max_connections=64,  # å¯¹åº”connectionPoolSize
            retry_on_timeout=True,
            socket_connect_timeout=5,
            socket_timeout=5
        )
        
        self.redis_client = redis.Redis(connection_pool=self.pool)
        self.test_results = {
            'connection_pool_tests': [],
            'retry_mechanism_tests': [],
            'concurrent_access_tests': [],
            'performance_metrics': {}
        }
    
    def test_connection_pool_efficiency(self, num_operations=1000):
        """æµ‹è¯•è¿æ¥æ± æ•ˆç‡"""
        print(f"\n=== è¿æ¥æ± æ•ˆç‡æµ‹è¯• (æ“ä½œæ•°: {num_operations}) ===")
        
        start_time = time.time()
        success_count = 0
        error_count = 0
        response_times = []
        
        for i in range(num_operations):
            try:
                op_start = time.time()
                
                # æ‰§è¡ŒRedisæ“ä½œ
                key = f"test_pool_{i}"
                self.redis_client.set(key, f"value_{i}", ex=60)
                result = self.redis_client.get(key)
                
                op_end = time.time()
                response_times.append((op_end - op_start) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
                success_count += 1
                
                if i % 100 == 0:
                    print(f"å·²å®Œæˆ {i}/{num_operations} æ“ä½œ")
                    
            except Exception as e:
                error_count += 1
                print(f"æ“ä½œ {i} å¤±è´¥: {e}")
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        avg_response_time = statistics.mean(response_times) if response_times else 0
        p95_response_time = statistics.quantiles(response_times, n=20)[18] if len(response_times) > 20 else 0
        
        pool_stats = {
            'total_operations': num_operations,
            'success_count': success_count,
            'error_count': error_count,
            'success_rate': (success_count / num_operations) * 100,
            'total_time_seconds': total_time,
            'operations_per_second': num_operations / total_time,
            'avg_response_time_ms': avg_response_time,
            'p95_response_time_ms': p95_response_time,
            'pool_max_connections': 64
        }
        
        self.test_results['connection_pool_tests'].append(pool_stats)
        
        print(f"æˆåŠŸç‡: {pool_stats['success_rate']:.2f}%")
        print(f"å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ms")
        print(f"P95å“åº”æ—¶é—´: {p95_response_time:.2f}ms")
        print(f"æ¯ç§’æ“ä½œæ•°: {pool_stats['operations_per_second']:.2f}")
        
        return pool_stats
    
    def test_concurrent_access(self, num_threads=20, operations_per_thread=50):
        """æµ‹è¯•å¹¶å‘è®¿é—®èƒ½åŠ›"""
        print(f"\n=== å¹¶å‘è®¿é—®æµ‹è¯• (çº¿ç¨‹æ•°: {num_threads}, æ¯çº¿ç¨‹æ“ä½œæ•°: {operations_per_thread}) ===")
        
        def worker_thread(thread_id):
            thread_results = {'success': 0, 'error': 0, 'response_times': []}
            
            for i in range(operations_per_thread):
                try:
                    start_time = time.time()
                    
                    key = f"concurrent_test_{thread_id}_{i}"
                    self.redis_client.set(key, f"thread_{thread_id}_value_{i}", ex=60)
                    result = self.redis_client.get(key)
                    
                    end_time = time.time()
                    thread_results['response_times'].append((end_time - start_time) * 1000)
                    thread_results['success'] += 1
                    
                except Exception as e:
                    thread_results['error'] += 1
                    print(f"çº¿ç¨‹ {thread_id} æ“ä½œ {i} å¤±è´¥: {e}")
            
            return thread_results
        
        start_time = time.time()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [executor.submit(worker_thread, i) for i in range(num_threads)]
            thread_results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        end_time = time.time()
        
        # æ±‡æ€»ç»“æœ
        total_success = sum(r['success'] for r in thread_results)
        total_error = sum(r['error'] for r in thread_results)
        total_operations = num_threads * operations_per_thread
        all_response_times = []
        for r in thread_results:
            all_response_times.extend(r['response_times'])
        
        concurrent_stats = {
            'num_threads': num_threads,
            'operations_per_thread': operations_per_thread,
            'total_operations': total_operations,
            'total_success': total_success,
            'total_error': total_error,
            'success_rate': (total_success / total_operations) * 100,
            'total_time_seconds': end_time - start_time,
            'concurrent_ops_per_second': total_operations / (end_time - start_time),
            'avg_response_time_ms': statistics.mean(all_response_times) if all_response_times else 0,
            'p95_response_time_ms': statistics.quantiles(all_response_times, n=20)[18] if len(all_response_times) > 20 else 0
        }
        
        self.test_results['concurrent_access_tests'].append(concurrent_stats)
        
        print(f"å¹¶å‘æˆåŠŸç‡: {concurrent_stats['success_rate']:.2f}%")
        print(f"å¹¶å‘æ¯ç§’æ“ä½œæ•°: {concurrent_stats['concurrent_ops_per_second']:.2f}")
        print(f"å¹¶å‘å¹³å‡å“åº”æ—¶é—´: {concurrent_stats['avg_response_time_ms']:.2f}ms")
        
        return concurrent_stats
    
    def test_retry_mechanism(self, num_tests=10):
        """æµ‹è¯•é‡è¯•æœºåˆ¶ï¼ˆæ¨¡æ‹Ÿç½‘ç»œå¼‚å¸¸ï¼‰"""
        print(f"\n=== é‡è¯•æœºåˆ¶æµ‹è¯• (æµ‹è¯•æ¬¡æ•°: {num_tests}) ===")
        
        retry_results = []
        
        for i in range(num_tests):
            try:
                # ä½¿ç”¨çŸ­è¶…æ—¶æ¥æ¨¡æ‹Ÿç½‘ç»œé—®é¢˜
                test_client = redis.Redis(
                    host=self.host,
                    port=self.port,
                    db=self.db,
                    password=self.password,
                    socket_timeout=0.1,  # æçŸ­è¶…æ—¶
                    retry_on_timeout=True
                )
                
                start_time = time.time()
                key = f"retry_test_{i}"
                
                try:
                    test_client.set(key, f"retry_value_{i}")
                    result = test_client.get(key)
                    success = True
                except Exception as e:
                    success = False
                    print(f"é‡è¯•æµ‹è¯• {i} å¤±è´¥: {e}")
                
                end_time = time.time()
                
                retry_results.append({
                    'test_id': i,
                    'success': success,
                    'response_time_ms': (end_time - start_time) * 1000
                })
                
            except Exception as e:
                print(f"é‡è¯•æµ‹è¯• {i} é…ç½®å¤±è´¥: {e}")
                retry_results.append({
                    'test_id': i,
                    'success': False,
                    'response_time_ms': 0
                })
        
        success_count = sum(1 for r in retry_results if r['success'])
        retry_stats = {
            'total_tests': num_tests,
            'success_count': success_count,
            'success_rate': (success_count / num_tests) * 100,
            'avg_response_time_ms': statistics.mean([r['response_time_ms'] for r in retry_results if r['success']])
        }
        
        self.test_results['retry_mechanism_tests'].append(retry_stats)
        
        print(f"é‡è¯•æˆåŠŸç‡: {retry_stats['success_rate']:.2f}%")
        print(f"é‡è¯•å¹³å‡å“åº”æ—¶é—´: {retry_stats['avg_response_time_ms']:.2f}ms")
        
        return retry_stats
    
    def run_comprehensive_test(self):
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        print("\n" + "="*60)
        print("Redisè¿æ¥ç¨³å®šæ€§ç»¼åˆæµ‹è¯•å¼€å§‹")
        print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)
        
        try:
            # æµ‹è¯•åŸºæœ¬è¿æ¥
            print("\n>>> æµ‹è¯•Redisè¿æ¥...")
            self.redis_client.ping()
            print("âœ“ Redisè¿æ¥æ­£å¸¸")
            
            # 1. è¿æ¥æ± æ•ˆç‡æµ‹è¯•
            pool_stats = self.test_connection_pool_efficiency(1000)
            
            # 2. å¹¶å‘è®¿é—®æµ‹è¯•
            concurrent_stats = self.test_concurrent_access(20, 50)
            
            # 3. é‡è¯•æœºåˆ¶æµ‹è¯•
            retry_stats = self.test_retry_mechanism(10)
            
            # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
            self.generate_test_report()
            
        except Exception as e:
            print(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
        
        return True
    
    def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("æµ‹è¯•æŠ¥å‘Š")
        print("="*60)
        
        # è¿æ¥æ± æµ‹è¯•ç»“æœ
        if self.test_results['connection_pool_tests']:
            pool_test = self.test_results['connection_pool_tests'][0]
            print(f"\nğŸ“Š è¿æ¥æ± æ€§èƒ½:")
            print(f"  - æˆåŠŸç‡: {pool_test['success_rate']:.2f}%")
            print(f"  - æ¯ç§’æ“ä½œæ•°: {pool_test['operations_per_second']:.2f}")
            print(f"  - å¹³å‡å“åº”æ—¶é—´: {pool_test['avg_response_time_ms']:.2f}ms")
            print(f"  - P95å“åº”æ—¶é—´: {pool_test['p95_response_time_ms']:.2f}ms")
        
        # å¹¶å‘æµ‹è¯•ç»“æœ
        if self.test_results['concurrent_access_tests']:
            concurrent_test = self.test_results['concurrent_access_tests'][0]
            print(f"\nğŸš€ å¹¶å‘æ€§èƒ½:")
            print(f"  - å¹¶å‘æˆåŠŸç‡: {concurrent_test['success_rate']:.2f}%")
            print(f"  - å¹¶å‘æ¯ç§’æ“ä½œæ•°: {concurrent_test['concurrent_ops_per_second']:.2f}")
            print(f"  - å¹¶å‘å¹³å‡å“åº”æ—¶é—´: {concurrent_test['avg_response_time_ms']:.2f}ms")
        
        # é‡è¯•æœºåˆ¶ç»“æœ
        if self.test_results['retry_mechanism_tests']:
            retry_test = self.test_results['retry_mechanism_tests'][0]
            print(f"\nğŸ”„ é‡è¯•æœºåˆ¶:")
            print(f"  - é‡è¯•æˆåŠŸç‡: {retry_test['success_rate']:.2f}%")
            print(f"  - é‡è¯•å¹³å‡å“åº”æ—¶é—´: {retry_test['avg_response_time_ms']:.2f}ms")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_file = f"redis_stability_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        # ç»™å‡ºä¼˜åŒ–å»ºè®®
        self.provide_optimization_suggestions()
    
    def provide_optimization_suggestions(self):
        """æä¾›ä¼˜åŒ–å»ºè®®"""
        print("\n" + "="*60)
        print("ä¼˜åŒ–å»ºè®®")
        print("="*60)
        
        suggestions = []
        
        # åŸºäºæµ‹è¯•ç»“æœç»™å‡ºå»ºè®®
        if self.test_results['connection_pool_tests']:
            pool_test = self.test_results['connection_pool_tests'][0]
            if pool_test['success_rate'] < 99:
                suggestions.append("ğŸ”§ è¿æ¥æ± æˆåŠŸç‡åä½ï¼Œå»ºè®®å¢åŠ è¿æ¥æ± å¤§å°æˆ–æ£€æŸ¥ç½‘ç»œç¨³å®šæ€§")
            if pool_test['avg_response_time_ms'] > 10:
                suggestions.append("âš¡ å¹³å‡å“åº”æ—¶é—´è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–ç½‘ç»œé…ç½®æˆ–å¢åŠ æœ€å°ç©ºé—²è¿æ¥æ•°")
        
        if self.test_results['concurrent_access_tests']:
            concurrent_test = self.test_results['concurrent_access_tests'][0]
            if concurrent_test['success_rate'] < 95:
                suggestions.append("ğŸš€ å¹¶å‘æˆåŠŸç‡åä½ï¼Œå»ºè®®å¢åŠ è¿æ¥æ± å¤§å°è‡³128æˆ–ä¼˜åŒ–è¶…æ—¶é…ç½®")
        
        if self.test_results['retry_mechanism_tests']:
            retry_test = self.test_results['retry_mechanism_tests'][0]
            if retry_test['success_rate'] < 80:
                suggestions.append("ğŸ”„ é‡è¯•æœºåˆ¶æ•ˆæœä¸ä½³ï¼Œå»ºè®®è°ƒæ•´é‡è¯•æ¬¡æ•°è‡³5æ¬¡æˆ–å¢åŠ é‡è¯•é—´éš”")
        
        if not suggestions:
            suggestions.append("âœ… å½“å‰é…ç½®è¡¨ç°è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ç›‘æ§ç”Ÿäº§ç¯å¢ƒæ€§èƒ½")
        
        for i, suggestion in enumerate(suggestions, 1):
            print(f"{i}. {suggestion}")
        
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("1. åœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²é…ç½®")
        print("2. è®¾ç½®ç›‘æ§å‘Šè­¦é˜ˆå€¼")
        print("3. å®šæœŸè¿è¡Œæ­¤æµ‹è¯•è„šæœ¬")
        print("4. æ ¹æ®å®é™…è´Ÿè½½è°ƒæ•´å‚æ•°")

def main():
    """ä¸»å‡½æ•°"""
    print("Redisè¿æ¥ç¨³å®šæ€§æµ‹è¯•ç¨‹åº")
    print("æµ‹è¯•Java Redissoné…ç½®çš„è¿æ¥æ± å’Œé‡è¯•æœºåˆ¶æ•ˆæœ")
    
    # é…ç½®Redisè¿æ¥å‚æ•°ï¼ˆæ ¹æ®å®é™…ç¯å¢ƒè°ƒæ•´ï¼‰
    tester = RedisStabilityTester(
        host='localhost',
        port=6379,
        db=0,
        password=None  # å¦‚æœæœ‰å¯†ç è¯·è®¾ç½®
    )
    
    # è¿è¡Œç»¼åˆæµ‹è¯•
    success = tester.run_comprehensive_test()
    
    if success:
        print("\nâœ… æµ‹è¯•å®Œæˆï¼")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())